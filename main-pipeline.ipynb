{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets torch scikit-learn matplotlib sentencepiece\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:53:53.163334Z","iopub.execute_input":"2025-08-11T10:53:53.163496Z","iopub.status.idle":"2025-08-11T10:53:56.546538Z","shell.execute_reply.started":"2025-08-11T10:53:53.163475Z","shell.execute_reply":"2025-08-11T10:53:56.545817Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!git clone https://github.com/bharathichezhiyan/DravidianCodeMix-Dataset.git\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:54:09.092378Z","iopub.execute_input":"2025-08-11T10:54:09.092656Z","iopub.status.idle":"2025-08-11T10:54:11.114401Z","shell.execute_reply.started":"2025-08-11T10:54:09.092624Z","shell.execute_reply":"2025-08-11T10:54:11.113626Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'DravidianCodeMix-Dataset'...\nremote: Enumerating objects: 81, done.\u001b[K\nremote: Total 81 (delta 0), reused 0 (delta 0), pack-reused 81 (from 1)\u001b[K\nReceiving objects: 100% (81/81), 19.56 MiB | 18.82 MiB/s, done.\nResolving deltas: 100% (36/36), done.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!cd DravidianCodeMix-Dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:54:18.836433Z","iopub.execute_input":"2025-08-11T10:54:18.836696Z","iopub.status.idle":"2025-08-11T10:54:18.952974Z","shell.execute_reply.started":"2025-08-11T10:54:18.836671Z","shell.execute_reply":"2025-08-11T10:54:18.952153Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import os\n\n# View the files/directories inside DravidianCodeMix-Dataset\nprint(os.listdir(\"DravidianCodeMix-Dataset\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:54:27.152359Z","iopub.execute_input":"2025-08-11T10:54:27.152963Z","iopub.status.idle":"2025-08-11T10:54:27.157950Z","shell.execute_reply.started":"2025-08-11T10:54:27.152928Z","shell.execute_reply":"2025-08-11T10:54:27.157233Z"}},"outputs":[{"name":"stdout","text":"['.git', 'programs', 'DravidianCodeMix-2020.zip', 'README.md']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!unzip DravidianCodeMix-Dataset/DravidianCodeMix-2020.zip -d DravidianCodeMix-Dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:54:30.299395Z","iopub.execute_input":"2025-08-11T10:54:30.299652Z","iopub.status.idle":"2025-08-11T10:54:30.705803Z","shell.execute_reply.started":"2025-08-11T10:54:30.299630Z","shell.execute_reply":"2025-08-11T10:54:30.704953Z"}},"outputs":[{"name":"stdout","text":"Archive:  DravidianCodeMix-Dataset/DravidianCodeMix-2020.zip\n   creating: DravidianCodeMix-Dataset/DravidianCodeMix/\n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/tamil_sentiment_full_train.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/tamil_sentiment_full.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/tamil_offensive_full_train.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/tamil_offensive_full_test.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/tamil_offensive_full_dev.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/tamil_offensive_full.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/mal_full_sentiment_train.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/mal_full_sentiment_test.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/mal_full_sentiment_dev.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/mal_full_sentiment.tsv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/mal_full_offensive_train.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/kannada_sentiment_train.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/kannada_sentiment_test.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/kannada_sentiment_dev.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/kannada_offensive_train.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/kannada_offensive_test.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/kannada_offensive_dev.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/mal_full_offensive_test.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/mal_full_offensive_dev.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/mal_full_offensive.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/kannada_offensive.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/kannada_sentiment.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/tamil_sentiment_full_test.csv  \n  inflating: DravidianCodeMix-Dataset/DravidianCodeMix/tamil_sentiment_full_dev.csv  \n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!head -n 10 DravidianCodeMix-Dataset/DravidianCodeMix/tamil_sentiment_full_train.csv\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:54:39.803359Z","iopub.execute_input":"2025-08-11T10:54:39.804022Z","iopub.status.idle":"2025-08-11T10:54:39.923223Z","shell.execute_reply.started":"2025-08-11T10:54:39.803987Z","shell.execute_reply":"2025-08-11T10:54:39.922514Z"}},"outputs":[{"name":"stdout","text":"First like button vijay setupati fans\tunknown_state\nVetri ne dhanusha pudiche thongitu iru....\tPositive\nIthu romba naal ku munnadi Short film'a pathathu! (Short film name: Kekka bukka kekka bukka)Short film'e Super'a irrukum!\tPositive\nTrending no1 in srilanka.... june 16\tPositive\nMaja thala marana  mass thala\tPositive\nThala thala thala solla vaarthtai illai\tPositive\nJayam Ravi thalaivar kitta bagiranga mannippu kekkalanna indha padatha purakkanippom Twitter hashtag pathingala thalaivar fans power Ra Boycot comali\tPositive\nPadam asuran madhiri oduna na motta adichikuren\tMixed_feelings\nSemma trailer super surya fans like\tunknown_state\nSurya is super Surya fans like adikku makkaallleeee\tPositive\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import os\nprint(os.listdir(\"DravidianCodeMix-Dataset/DravidianCodeMix\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:54:47.749468Z","iopub.execute_input":"2025-08-11T10:54:47.750213Z","iopub.status.idle":"2025-08-11T10:54:47.754731Z","shell.execute_reply.started":"2025-08-11T10:54:47.750154Z","shell.execute_reply":"2025-08-11T10:54:47.754135Z"}},"outputs":[{"name":"stdout","text":"['tamil_sentiment_full_train.csv', 'mal_full_sentiment_test.csv', 'tamil_offensive_full_dev.csv', 'tamil_sentiment_full_test.csv', 'tamil_offensive_full_test.csv', 'tamil_sentiment_full.csv', 'mal_full_sentiment.tsv', 'tamil_offensive_full.csv', 'kannada_offensive_train.csv', 'kannada_offensive_dev.csv', 'tamil_sentiment_full_dev.csv', 'mal_full_sentiment_train.csv', 'kannada_sentiment_train.csv', 'mal_full_offensive_dev.csv', 'kannada_sentiment_dev.csv', 'mal_full_offensive_train.csv', 'kannada_sentiment.csv', 'tamil_offensive_full_train.csv', 'kannada_sentiment_test.csv', 'kannada_offensive.csv', 'kannada_offensive_test.csv', 'mal_full_offensive_test.csv', 'mal_full_sentiment_dev.csv', 'mal_full_offensive.csv']\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import os\n\nprint(\"Current working directory:\", os.getcwd())\nprint(\"Files/folders here:\", os.listdir())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:54:52.833164Z","iopub.execute_input":"2025-08-11T10:54:52.833920Z","iopub.status.idle":"2025-08-11T10:54:52.838056Z","shell.execute_reply.started":"2025-08-11T10:54:52.833892Z","shell.execute_reply":"2025-08-11T10:54:52.837451Z"}},"outputs":[{"name":"stdout","text":"Current working directory: /kaggle/working\nFiles/folders here: ['.virtual_documents', 'DravidianCodeMix-Dataset']\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\n\nbase_path = \"DravidianCodeMix-Dataset/DravidianCodeMix/\"\n\n# Load train/dev/test files for Tamil Sentiment\ntrain_df = pd.read_csv(base_path + \"tamil_sentiment_full_train.csv\", sep=\",\", encoding=\"utf-8\", on_bad_lines=\"skip\")\ndev_df   = pd.read_csv(base_path + \"tamil_sentiment_full_dev.csv\", sep=\",\", encoding=\"utf-8\", on_bad_lines=\"skip\")\ntest_df  = pd.read_csv(base_path + \"tamil_sentiment_full_test.csv\", sep=\",\", encoding=\"utf-8\", on_bad_lines=\"skip\")\n\nprint(\"Train shape:\", train_df.shape)\nprint(train_df.head())\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:55:16.762244Z","iopub.execute_input":"2025-08-11T10:55:16.763021Z","iopub.status.idle":"2025-08-11T10:55:17.121201Z","shell.execute_reply.started":"2025-08-11T10:55:16.762992Z","shell.execute_reply":"2025-08-11T10:55:17.120566Z"}},"outputs":[{"name":"stdout","text":"Train shape: (32471, 1)\n  First like button vijay setupati fans\\tunknown_state\n0  Vetri ne dhanusha pudiche thongitu iru....\\tPo...  \n1  Ithu romba naal ku munnadi Short film'a pathat...  \n2     Trending no1 in srilanka.... june 16\\tPositive  \n3            Maja thala marana  mass thala\\tPositive  \n4  Thala thala thala solla vaarthtai illai\\tPositive  \n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import pandas as pd\n\nbase_path = \"DravidianCodeMix-Dataset/DravidianCodeMix/\"\n\n# Load train/dev/test files for Tamil Sentiment\ntrain_df = pd.read_csv(base_path + \"tamil_sentiment_full_train.csv\", sep=\"\\t\", encoding=\"utf-8\", on_bad_lines=\"skip\")\ndev_df   = pd.read_csv(base_path + \"tamil_sentiment_full_dev.csv\", sep=\"\\t\", encoding=\"utf-8\", on_bad_lines=\"skip\")\ntest_df  = pd.read_csv(base_path + \"tamil_sentiment_full_test.csv\", sep=\"\\t\", encoding=\"utf-8\", on_bad_lines=\"skip\")\n\nprint(\"Train shape:\", train_df.shape)\nprint(train_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:55:41.301626Z","iopub.execute_input":"2025-08-11T10:55:41.301902Z","iopub.status.idle":"2025-08-11T10:55:41.390905Z","shell.execute_reply.started":"2025-08-11T10:55:41.301883Z","shell.execute_reply":"2025-08-11T10:55:41.390331Z"}},"outputs":[{"name":"stdout","text":"Train shape: (35191, 2)\n               First like button vijay setupati fans unknown_state\n0         Vetri ne dhanusha pudiche thongitu iru....      Positive\n1  Ithu romba naal ku munnadi Short film'a pathat...      Positive\n2               Trending no1 in srilanka.... june 16      Positive\n3                      Maja thala marana  mass thala      Positive\n4            Thala thala thala solla vaarthtai illai      Positive\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"train_df.columns = [\"text\", \"label\"]\nprint(train_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:55:53.563122Z","iopub.execute_input":"2025-08-11T10:55:53.563393Z","iopub.status.idle":"2025-08-11T10:55:53.569291Z","shell.execute_reply.started":"2025-08-11T10:55:53.563373Z","shell.execute_reply":"2025-08-11T10:55:53.568579Z"}},"outputs":[{"name":"stdout","text":"                                                text     label\n0         Vetri ne dhanusha pudiche thongitu iru....  Positive\n1  Ithu romba naal ku munnadi Short film'a pathat...  Positive\n2               Trending no1 in srilanka.... june 16  Positive\n3                      Maja thala marana  mass thala  Positive\n4            Thala thala thala solla vaarthtai illai  Positive\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import re\n\ndef clean_text(text):\n    text = str(text).lower()\n    text = re.sub(r\"http\\S+\", \"\", text)                   # remove URLs\n    text = re.sub(r\"[^a-zA-Z\\u0B80-\\u0BFF\\s]\", \" \", text) # keep Tamil+English\n    text = re.sub(r\"\\s+\", \" \", text).strip()              # remove extra spaces\n    return text\n\ntrain_df[\"clean_text\"] = train_df[\"text\"].apply(clean_text)\nprint(train_df[[\"text\", \"clean_text\", \"label\"]].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:55:57.022704Z","iopub.execute_input":"2025-08-11T10:55:57.022973Z","iopub.status.idle":"2025-08-11T10:55:57.341017Z","shell.execute_reply.started":"2025-08-11T10:55:57.022949Z","shell.execute_reply":"2025-08-11T10:55:57.340236Z"}},"outputs":[{"name":"stdout","text":"                                                text  \\\n0         Vetri ne dhanusha pudiche thongitu iru....   \n1  Ithu romba naal ku munnadi Short film'a pathat...   \n2               Trending no1 in srilanka.... june 16   \n3                      Maja thala marana  mass thala   \n4            Thala thala thala solla vaarthtai illai   \n\n                                          clean_text     label  \n0             vetri ne dhanusha pudiche thongitu iru  Positive  \n1  ithu romba naal ku munnadi short film a pathat...  Positive  \n2                       trending no in srilanka june  Positive  \n3                       maja thala marana mass thala  Positive  \n4            thala thala thala solla vaarthtai illai  Positive  \n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"all_df = pd.concat([train_df, dev_df, test_df], ignore_index=True)\nprint(all_df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:56:03.754849Z","iopub.execute_input":"2025-08-11T10:56:03.755372Z","iopub.status.idle":"2025-08-11T10:56:03.764667Z","shell.execute_reply.started":"2025-08-11T10:56:03.755345Z","shell.execute_reply":"2025-08-11T10:56:03.763955Z"}},"outputs":[{"name":"stdout","text":"(43989, 5)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"sentiment_df = all_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:56:07.354560Z","iopub.execute_input":"2025-08-11T10:56:07.355019Z","iopub.status.idle":"2025-08-11T10:56:07.358603Z","shell.execute_reply.started":"2025-08-11T10:56:07.354994Z","shell.execute_reply":"2025-08-11T10:56:07.357856Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import pandas as pd\n\nbase_path = \"DravidianCodeMix-Dataset/DravidianCodeMix/\"\n\noffensive_train = pd.read_csv(\n    base_path + \"tamil_offensive_full_train.csv\",\n    sep=\"\\t\",               # tab-separated file\n    names=[\"text\", \"label\"],# force proper column names\n    usecols=[0, 1],         # only first 2 columns\n    encoding=\"utf-8\",\n    header=None,            # no header in these splits\n    quoting=3,              # ignore quotes\n    on_bad_lines=\"skip\"     # drop badly formatted rows\n)\n\nprint(offensive_train.shape)\nprint(offensive_train.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:56:10.335186Z","iopub.execute_input":"2025-08-11T10:56:10.335460Z","iopub.status.idle":"2025-08-11T10:56:10.405979Z","shell.execute_reply.started":"2025-08-11T10:56:10.335438Z","shell.execute_reply":"2025-08-11T10:56:10.405365Z"}},"outputs":[{"name":"stdout","text":"(35139, 2)\n                                                text          label\n0                  movie vara level la Erika poguthu  Not_offensive\n1  I love Ajith Kumar Vivegam movie inki mjy bht ...      not-Tamil\n2          Padam nalla comedy padama irukum polaye..  Not_offensive\n3  karthick subburaj anne .... intha padam vetri ...  Not_offensive\n4  கவுண்டர் தேவர்.சார்பாக வெற்றி பெற வாழ்த்துக்கள் 🦁  Not_offensive\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"train_df.columns = [\"text\", \"label\"]\nprint(train_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:56:17.942236Z","iopub.execute_input":"2025-08-11T10:56:17.942508Z","iopub.status.idle":"2025-08-11T10:56:18.033079Z","shell.execute_reply.started":"2025-08-11T10:56:17.942483Z","shell.execute_reply":"2025-08-11T10:56:18.032081Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1033288128.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6311\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6312\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6313\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6314\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6315\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mproperties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \"\"\"\n\u001b[1;32m    813\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;31m# Caller is responsible for ensuring we have an Index object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/base.py\u001b[0m in \u001b[0;36m_validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34mf\"values have {new_len} elements\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 3 elements, new values have 2 elements"],"ename":"ValueError","evalue":"Length mismatch: Expected axis has 3 elements, new values have 2 elements","output_type":"error"}],"execution_count":17},{"cell_type":"code","source":"import re\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r\"http\\S+\", \"\", text)\n    text = re.sub(r\"[^\\w\\s\\u0B80-\\u0BFF]\", \" \", text)  # Keep English/Tamil chars\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\n\ntrain_df[\"clean_text\"] = train_df[\"text\"].apply(clean_text)\nprint(train_df[[\"text\", \"clean_text\", \"label\"]].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:56:26.952439Z","iopub.execute_input":"2025-08-11T10:56:26.952720Z","iopub.status.idle":"2025-08-11T10:56:27.245586Z","shell.execute_reply.started":"2025-08-11T10:56:26.952697Z","shell.execute_reply":"2025-08-11T10:56:27.244894Z"}},"outputs":[{"name":"stdout","text":"                                                text  \\\n0         Vetri ne dhanusha pudiche thongitu iru....   \n1  Ithu romba naal ku munnadi Short film'a pathat...   \n2               Trending no1 in srilanka.... june 16   \n3                      Maja thala marana  mass thala   \n4            Thala thala thala solla vaarthtai illai   \n\n                                          clean_text     label  \n0             vetri ne dhanusha pudiche thongitu iru  Positive  \n1  ithu romba naal ku munnadi short film a pathat...  Positive  \n2                   trending no1 in srilanka june 16  Positive  \n3                       maja thala marana mass thala  Positive  \n4            thala thala thala solla vaarthtai illai  Positive  \n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import pandas as pd\n\nbase_path = \"DravidianCodeMix-Dataset/DravidianCodeMix/\"\n\ndef load_clean_tsv(filename):\n    \"\"\"Load a DravidianCodeMix TSV file correctly with only text+label columns.\"\"\"\n    return pd.read_csv(\n        base_path + filename,\n        sep=\"\\t\",                  # tab-separated\n        names=[\"text\", \"label\"],   # rename columns\n        usecols=[0, 1],             # only first two columns\n        encoding=\"utf-8\",\n        header=None,                # ignore first line if it has bad header\n        quoting=3,                  # disable quote processing\n        on_bad_lines=\"skip\"         # skip badly formatted lines\n    )\n\n# Load clean DataFrames\ntrain_df = load_clean_tsv(\"tamil_offensive_full_train.csv\")\ndev_df   = load_clean_tsv(\"tamil_offensive_full_dev.csv\")\ntest_df  = load_clean_tsv(\"tamil_offensive_full_test.csv\")\n\n# Merge them\nall_df = pd.concat([train_df, dev_df, test_df], ignore_index=True)\n\nprint(all_df.shape)\nprint(all_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:56:35.934136Z","iopub.execute_input":"2025-08-11T10:56:35.934734Z","iopub.status.idle":"2025-08-11T10:56:36.027395Z","shell.execute_reply.started":"2025-08-11T10:56:35.934710Z","shell.execute_reply":"2025-08-11T10:56:36.026608Z"}},"outputs":[{"name":"stdout","text":"(43919, 2)\n                                                text          label\n0                  movie vara level la Erika poguthu  Not_offensive\n1  I love Ajith Kumar Vivegam movie inki mjy bht ...      not-Tamil\n2          Padam nalla comedy padama irukum polaye..  Not_offensive\n3  karthick subburaj anne .... intha padam vetri ...  Not_offensive\n4  கவுண்டர் தேவர்.சார்பாக வெற்றி பெற வாழ்த்துக்கள் 🦁  Not_offensive\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import re\n\ndef clean_text(text):\n    text = str(text).lower()                        # lowercase\n    text = re.sub(r\"http\\S+\", \"\", text)              # remove URLs\n    text = re.sub(r\"[^a-zA-Z\\u0B80-\\u0BFF\\s]\", \" \", text)  # keep Tamil + English chars\n    text = re.sub(r\"\\s+\", \" \", text).strip()         # remove extra spaces\n    return text\n\nall_df[\"clean_text\"] = all_df[\"text\"].apply(clean_text)\n\nprint(all_df[[\"text\", \"clean_text\", \"label\"]].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:56:42.835659Z","iopub.execute_input":"2025-08-11T10:56:42.835899Z","iopub.status.idle":"2025-08-11T10:56:43.182040Z","shell.execute_reply.started":"2025-08-11T10:56:42.835880Z","shell.execute_reply":"2025-08-11T10:56:43.181202Z"}},"outputs":[{"name":"stdout","text":"                                                text  \\\n0                  movie vara level la Erika poguthu   \n1  I love Ajith Kumar Vivegam movie inki mjy bht ...   \n2          Padam nalla comedy padama irukum polaye..   \n3  karthick subburaj anne .... intha padam vetri ...   \n4  கவுண்டர் தேவர்.சார்பாக வெற்றி பெற வாழ்த்துக்கள் 🦁   \n\n                                          clean_text          label  \n0                  movie vara level la erika poguthu  Not_offensive  \n1  i love ajith kumar vivegam movie inki mjy bht ...      not-Tamil  \n2            padam nalla comedy padama irukum polaye  Not_offensive  \n3  karthick subburaj anne intha padam vetri adaya...  Not_offensive  \n4    கவுண்டர் தேவர் சார்பாக வெற்றி பெற வாழ்த்துக்கள்  Not_offensive  \n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"train_df = load_clean_tsv(\"tamil_offensive_full_train.csv\")\ndev_df = load_clean_tsv(\"tamil_offensive_full_dev.csv\")\ntest_df = load_clean_tsv(\"tamil_offensive_full_test.csv\")\nall_df = pd.concat([train_df, dev_df, test_df], ignore_index=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:56:49.464272Z","iopub.execute_input":"2025-08-11T10:56:49.464997Z","iopub.status.idle":"2025-08-11T10:56:49.555755Z","shell.execute_reply.started":"2025-08-11T10:56:49.464966Z","shell.execute_reply":"2025-08-11T10:56:49.555135Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"offensive_df = all_df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:56:52.764252Z","iopub.execute_input":"2025-08-11T10:56:52.764529Z","iopub.status.idle":"2025-08-11T10:56:52.768125Z","shell.execute_reply.started":"2025-08-11T10:56:52.764507Z","shell.execute_reply":"2025-08-11T10:56:52.767467Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming these are your two cleaned DataFrames\n# offensive_df, sentiment_df\n\n# Add a dataset identifier if you want to track sources\noffensive_df[\"task\"] = \"offensive\"\nsentiment_df[\"task\"] = \"sentiment\"\n\n# Combine\ncombined_df = pd.concat([offensive_df, sentiment_df], ignore_index=True)\n\nprint(combined_df.shape)\nprint(combined_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:56:55.626101Z","iopub.execute_input":"2025-08-11T10:56:55.626378Z","iopub.status.idle":"2025-08-11T10:56:55.647210Z","shell.execute_reply.started":"2025-08-11T10:56:55.626355Z","shell.execute_reply":"2025-08-11T10:56:55.646578Z"}},"outputs":[{"name":"stdout","text":"(87908, 6)\n                                                text          label  \\\n0                  movie vara level la Erika poguthu  Not_offensive   \n1  I love Ajith Kumar Vivegam movie inki mjy bht ...      not-Tamil   \n2          Padam nalla comedy padama irukum polaye..  Not_offensive   \n3  karthick subburaj anne .... intha padam vetri ...  Not_offensive   \n4  கவுண்டர் தேவர்.சார்பாக வெற்றி பெற வாழ்த்துக்கள் 🦁  Not_offensive   \n\n        task clean_text Kangana ranaut is perfect acting Jay lalita;Positive;  \\\n0  offensive        NaN                                                NaN      \n1  offensive        NaN                                                NaN      \n2  offensive        NaN                                                NaN      \n3  offensive        NaN                                                NaN      \n4  offensive        NaN                                                NaN      \n\n  வானம் திரைப்படத்தில் சிம்பு பணக்கார பெண்ணை எப்படி பணக்காரன் என்று காட்டிக் கொண்டு என்பது அனைவருக்கும் தெரியும் அப்போதெல்லாம் யாரும் பொங்குவில்லையே?;Mixed_feelings;  \n0                                                NaN                                                                                                                   \n1                                                NaN                                                                                                                   \n2                                                NaN                                                                                                                   \n3                                                NaN                                                                                                                   \n4                                                NaN                                                                                                                   \n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import random\ndef augment_code_mixed(text):\n    if not isinstance(text, str) or text.strip() == \"\":\n        return text  # or you can return \"\"\n    words = text.split()\n    if len(words) > 1:\n        idx = random.randint(0, len(words)-2)\n        words[idx], words[idx+1] = words[idx+1], words[idx]\n    return \" \".join(words)\n\n# Optionally, make sure there are no NaN:\ncombined_df[\"clean_text\"] = combined_df[\"clean_text\"].fillna('')\n\ncombined_df[\"augmented_text\"] = combined_df[\"clean_text\"].apply(augment_code_mixed)\nprint(combined_df[[\"clean_text\", \"augmented_text\"]].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:57:03.243304Z","iopub.execute_input":"2025-08-11T10:57:03.244009Z","iopub.status.idle":"2025-08-11T10:57:03.330247Z","shell.execute_reply.started":"2025-08-11T10:57:03.243986Z","shell.execute_reply":"2025-08-11T10:57:03.329519Z"}},"outputs":[{"name":"stdout","text":"  clean_text augmented_text\n0                          \n1                          \n2                          \n3                          \n4                          \n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import re\n\ndef clean_text_fn(text):\n    text = str(text).lower()  # convert to string and lowercase\n    text = re.sub(r\"http\\S+\", \"\", text)  # remove links\n    text = re.sub(r\"[^a-zA-Z\\u0B80-\\u0BFF\\s]\", \" \", text)  # keep Tamil + English\n    text = re.sub(r\"\\s+\", \" \", text).strip()  # remove extra spaces\n    return text\n\ncombined_df[\"clean_text\"] = combined_df[\"text\"].apply(clean_text_fn)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:57:10.821153Z","iopub.execute_input":"2025-08-11T10:57:10.821440Z","iopub.status.idle":"2025-08-11T10:57:11.438772Z","shell.execute_reply.started":"2025-08-11T10:57:10.821418Z","shell.execute_reply":"2025-08-11T10:57:11.438225Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Remove rows where clean_text is empty after cleaning\ncombined_df = combined_df[combined_df[\"clean_text\"] != \"\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:57:14.932244Z","iopub.execute_input":"2025-08-11T10:57:14.932947Z","iopub.status.idle":"2025-08-11T10:57:14.959929Z","shell.execute_reply.started":"2025-08-11T10:57:14.932915Z","shell.execute_reply":"2025-08-11T10:57:14.959351Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"import random\n\ndef augment_code_mixed(text):\n    words = text.split()\n    if len(words) > 1:\n        idx = random.randint(0, len(words)-2)\n        words[idx], words[idx+1] = words[idx+1], words[idx]\n    return \" \".join(words)\n\ncombined_df[\"augmented_text\"] = combined_df[\"clean_text\"].apply(augment_code_mixed)\n\nprint(combined_df[[\"clean_text\", \"augmented_text\"]].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:57:21.581068Z","iopub.execute_input":"2025-08-11T10:57:21.581666Z","iopub.status.idle":"2025-08-11T10:57:21.723490Z","shell.execute_reply.started":"2025-08-11T10:57:21.581637Z","shell.execute_reply":"2025-08-11T10:57:21.722904Z"}},"outputs":[{"name":"stdout","text":"                                          clean_text  \\\n0                  movie vara level la erika poguthu   \n1  i love ajith kumar vivegam movie inki mjy bht ...   \n2            padam nalla comedy padama irukum polaye   \n3  karthick subburaj anne intha padam vetri adaya...   \n4    கவுண்டர் தேவர் சார்பாக வெற்றி பெற வாழ்த்துக்கள்   \n\n                                      augmented_text  \n0                  movie level vara la erika poguthu  \n1  i love kumar ajith vivegam movie inki mjy bht ...  \n2            padam nalla comedy irukum padama polaye  \n3  karthick subburaj anne intha padam vetri unaga...  \n4    கவுண்டர் தேவர் சார்பாக வெற்றி வாழ்த்துக்கள் பெற  \n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"!pip install sacremoses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:58:33.285215Z","iopub.execute_input":"2025-08-11T10:58:33.286150Z","iopub.status.idle":"2025-08-11T10:58:37.524350Z","shell.execute_reply.started":"2025-08-11T10:58:33.286124Z","shell.execute_reply":"2025-08-11T10:58:37.523372Z"}},"outputs":[{"name":"stdout","text":"Collecting sacremoses\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacremoses) (2024.11.6)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses) (8.2.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses) (1.5.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sacremoses) (4.67.1)\nDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sacremoses\nSuccessfully installed sacremoses-0.1.1\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"from transformers import MarianMTModel, MarianTokenizer\nimport torch\n\nmodel_name = \"Helsinki-NLP/opus-mt-mul-en\"  # Use this instead of opus-mt-tam-en!\n\ntokenizer = MarianTokenizer.from_pretrained(model_name)\nmodel = MarianMTModel.from_pretrained(model_name)\n\ndef translate_texts(text_list):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    inputs = tokenizer(text_list, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n    outputs = model.generate(**inputs)\n    return [tokenizer.decode(t, skip_special_tokens=True) for t in outputs]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:58:45.063029Z","iopub.execute_input":"2025-08-11T10:58:45.063354Z","iopub.status.idle":"2025-08-11T10:58:46.893114Z","shell.execute_reply.started":"2025-08-11T10:58:45.063326Z","shell.execute_reply":"2025-08-11T10:58:46.892526Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"print(combined_df.columns)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:58:52.160648Z","iopub.execute_input":"2025-08-11T10:58:52.161038Z","iopub.status.idle":"2025-08-11T10:58:52.165535Z","shell.execute_reply.started":"2025-08-11T10:58:52.160918Z","shell.execute_reply":"2025-08-11T10:58:52.164788Z"}},"outputs":[{"name":"stdout","text":"Index(['text', 'label', 'task', 'clean_text',\n       'Kangana ranaut is perfect acting Jay lalita;Positive;',\n       'வானம் திரைப்படத்தில் சிம்பு பணக்கார பெண்ணை எப்படி பணக்காரன் என்று காட்டிக் கொண்டு என்பது அனைவருக்கும் தெரியும் அப்போதெல்லாம் யாரும் பொங்குவில்லையே?;Mixed_feelings;',\n       'augmented_text'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# Check how many NaNs are in the column you use (e.g., 'clean_text')\nprint(combined_df['clean_text'].isna().sum())\n\n# Option 1: Fill NaNs with empty strings before processing\ncombined_df['clean_text'] = combined_df['clean_text'].fillna('')\n\n# Option 2 (recommended if NaNs mean missing data): drop rows with NaN in 'clean_text'\ncombined_df = combined_df.dropna(subset=['clean_text'])\n\n# Now your data has no NaNs in 'clean_text' and can be safely vectorized or used for modeling\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:58:55.655264Z","iopub.execute_input":"2025-08-11T10:58:55.655545Z","iopub.status.idle":"2025-08-11T10:58:55.723321Z","shell.execute_reply.started":"2025-08-11T10:58:55.655521Z","shell.execute_reply":"2025-08-11T10:58:55.722639Z"}},"outputs":[{"name":"stdout","text":"0\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"import random\n\ndef augment_code_mixed(text):\n    words = text.split()\n    if len(words) > 1:\n        idx = random.randint(0, len(words)-2)\n        words[idx], words[idx+1] = words[idx+1], words[idx]\n    return \" \".join(words)\n\ncombined_df[\"augmented_text\"] = combined_df[\"clean_text\"].apply(augment_code_mixed)\nprint(combined_df[[\"clean_text\", \"augmented_text\"]].head())\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:59:02.639987Z","iopub.execute_input":"2025-08-11T10:59:02.640732Z","iopub.status.idle":"2025-08-11T10:59:02.778740Z","shell.execute_reply.started":"2025-08-11T10:59:02.640707Z","shell.execute_reply":"2025-08-11T10:59:02.778028Z"}},"outputs":[{"name":"stdout","text":"                                          clean_text  \\\n0                  movie vara level la erika poguthu   \n1  i love ajith kumar vivegam movie inki mjy bht ...   \n2            padam nalla comedy padama irukum polaye   \n3  karthick subburaj anne intha padam vetri adaya...   \n4    கவுண்டர் தேவர் சார்பாக வெற்றி பெற வாழ்த்துக்கள்   \n\n                                      augmented_text  \n0                  movie level vara la erika poguthu  \n1  i love ajith kumar vivegam movie inki mjy bht ...  \n2            padam nalla comedy irukum padama polaye  \n3  karthick subburaj anne intha padam vetri adaya...  \n4    கவுண்டர் தேவர் வெற்றி சார்பாக பெற வாழ்த்துக்கள்  \n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"print(train_df['label'].isna().sum())\nprint(test_df['label'].isna().sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:59:09.927730Z","iopub.execute_input":"2025-08-11T10:59:09.928091Z","iopub.status.idle":"2025-08-11T10:59:09.934808Z","shell.execute_reply.started":"2025-08-11T10:59:09.928069Z","shell.execute_reply":"2025-08-11T10:59:09.933976Z"}},"outputs":[{"name":"stdout","text":"0\n0\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# Drop any training rows with missing label\ntrain_df = train_df.dropna(subset=['label'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:59:17.234381Z","iopub.execute_input":"2025-08-11T10:59:17.234853Z","iopub.status.idle":"2025-08-11T10:59:17.243222Z","shell.execute_reply.started":"2025-08-11T10:59:17.234825Z","shell.execute_reply":"2025-08-11T10:59:17.242478Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"test_df = test_df.dropna(subset=['label'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:59:20.481547Z","iopub.execute_input":"2025-08-11T10:59:20.482311Z","iopub.status.idle":"2025-08-11T10:59:20.487848Z","shell.execute_reply.started":"2025-08-11T10:59:20.482282Z","shell.execute_reply":"2025-08-11T10:59:20.486995Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# Drop rows with NaN or empty strings in critical columns\ncombined_df = combined_df.dropna(subset=['clean_text', 'label'])\n\n# Also remove empty or whitespace-only labels or texts\ncombined_df = combined_df[\n    (combined_df['clean_text'].astype(str).str.strip() != '') &\n    (combined_df['label'].astype(str).str.strip() != '')\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:59:24.090349Z","iopub.execute_input":"2025-08-11T10:59:24.090645Z","iopub.status.idle":"2025-08-11T10:59:24.178362Z","shell.execute_reply.started":"2025-08-11T10:59:24.090621Z","shell.execute_reply":"2025-08-11T10:59:24.177613Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, test_df = train_test_split(combined_df, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:59:30.909884Z","iopub.execute_input":"2025-08-11T10:59:30.910642Z","iopub.status.idle":"2025-08-11T10:59:30.945026Z","shell.execute_reply.started":"2025-08-11T10:59:30.910613Z","shell.execute_reply":"2025-08-11T10:59:30.944384Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"print(\"NaNs in train labels:\", train_df['label'].isna().sum())\nprint(\"NaNs in test labels:\", test_df['label'].isna().sum())\nprint(\"Empty train labels:\", (train_df['label'].astype(str).str.strip() == '').sum())\nprint(\"Empty test labels:\", (test_df['label'].astype(str).str.strip() == '').sum())\nprint(\"NaNs in train clean_text:\", train_df['clean_text'].isna().sum())\nprint(\"NaNs in test clean_text:\", test_df['clean_text'].isna().sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:59:35.583444Z","iopub.execute_input":"2025-08-11T10:59:35.584063Z","iopub.status.idle":"2025-08-11T10:59:35.621264Z","shell.execute_reply.started":"2025-08-11T10:59:35.584036Z","shell.execute_reply":"2025-08-11T10:59:35.620517Z"}},"outputs":[{"name":"stdout","text":"NaNs in train labels: 0\nNaNs in test labels: 0\nEmpty train labels: 0\nEmpty test labels: 0\nNaNs in train clean_text: 0\nNaNs in test clean_text: 0\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# List out valid labels based on task\nvalid_labels = [\n    'Not_offensive', 'Offensive_Targeted_Insult_Group', 'Offensive_Targeted_Insult_Individual',\n    'Offensive_Targeted_Insult_Other', 'Offensive_Untargetede', 'not-Tamil',\n    'Positive', 'Negative', 'Mixed_feelings', 'unknown_state'\n]\ncombined_df = combined_df[combined_df['label'].isin(valid_labels)]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:59:41.855123Z","iopub.execute_input":"2025-08-11T10:59:41.855439Z","iopub.status.idle":"2025-08-11T10:59:41.876318Z","shell.execute_reply.started":"2025-08-11T10:59:41.855417Z","shell.execute_reply":"2025-08-11T10:59:41.875665Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"combined_df = combined_df.dropna(subset=['clean_text', 'label'])\ncombined_df = combined_df[\n    (combined_df['clean_text'].str.strip() != '') &\n    (combined_df['label'].str.strip() != '')\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:59:54.917096Z","iopub.execute_input":"2025-08-11T10:59:54.917682Z","iopub.status.idle":"2025-08-11T10:59:54.975921Z","shell.execute_reply.started":"2025-08-11T10:59:54.917657Z","shell.execute_reply":"2025-08-11T10:59:54.975212Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\n\n# Make sure you have no NaN or empty values\ncombined_df = combined_df.dropna(subset=['clean_text', 'label'])\ncombined_df = combined_df[\n    (combined_df['clean_text'].astype(str).str.strip() != '') &\n    (combined_df['label'].astype(str).str.strip() != '')\n]\n\n# Train/test split (stratified to preserve label distribution)\ntrain_df, test_df = train_test_split(\n    combined_df,\n    test_size=0.2,\n    random_state=42,\n    stratify=combined_df['label']\n)\n\n# Vectorize text\nvec = TfidfVectorizer()\nX_train = vec.fit_transform(train_df[\"clean_text\"])\nX_test = vec.transform(test_df[\"clean_text\"])\n\n# Define the classifier\nclf = LogisticRegression(max_iter=2000, class_weight='balanced')  # helps with imbalance\n\n# Train\nclf.fit(X_train, train_df[\"label\"])\n\n# Predict\ny_pred = clf.predict(X_test)\n\n# Evaluate\nprint(classification_report(test_df[\"label\"], y_pred, zero_division=0))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:00:01.455167Z","iopub.execute_input":"2025-08-11T11:00:01.456031Z","iopub.status.idle":"2025-08-11T11:00:49.954597Z","shell.execute_reply.started":"2025-08-11T11:00:01.456001Z","shell.execute_reply":"2025-08-11T11:00:49.953983Z"}},"outputs":[{"name":"stdout","text":"                                      precision    recall  f1-score   support\n\n                      Mixed_feelings       0.07      0.12      0.09       781\n                            Negative       0.05      0.06      0.05       832\n                       Not_offensive       0.32      0.10      0.15      6361\n     Offensive_Targeted_Insult_Group       0.11      0.22      0.15       628\nOffensive_Targeted_Insult_Individual       0.13      0.27      0.17       593\n     Offensive_Targeted_Insult_Other       0.02      0.05      0.03       118\n               Offensive_Untargetede       0.15      0.28      0.20       726\n                            Positive       0.31      0.30      0.30      3981\n                           not-Tamil       0.47      0.78      0.59       671\n                       unknown_state       0.18      0.35      0.24      1107\n\n                            accuracy                           0.22     15798\n                           macro avg       0.18      0.25      0.20     15798\n                        weighted avg       0.26      0.22      0.21     15798\n\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"# Create augmented data\ncombined_df[\"augmented_text\"] = combined_df[\"clean_text\"].apply(augment_code_mixed)\n\n# Combine original and augmented data\naugmented_df = pd.concat([\n    combined_df[[\"clean_text\", \"label\"]].rename(columns={\"clean_text\": \"text\"}),\n    combined_df[[\"augmented_text\", \"label\"]].rename(columns={\"augmented_text\": \"text\"})\n], ignore_index=True)\n\n# Remove empty or NaN text\naugmented_df = augmented_df.dropna(subset=['text', 'label'])\naugmented_df = augmented_df[(augmented_df['text'].str.strip() != '') & (augmented_df['label'].str.strip() != '')]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:01:43.532832Z","iopub.execute_input":"2025-08-11T11:01:43.533455Z","iopub.status.idle":"2025-08-11T11:01:43.776027Z","shell.execute_reply.started":"2025-08-11T11:01:43.533428Z","shell.execute_reply":"2025-08-11T11:01:43.775121Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"train_aug, test_aug = train_test_split(\n    augmented_df,\n    test_size=0.2,\n    random_state=42,\n    stratify=augmented_df['label']\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:02:14.054725Z","iopub.execute_input":"2025-08-11T11:02:14.055385Z","iopub.status.idle":"2025-08-11T11:02:14.196499Z","shell.execute_reply.started":"2025-08-11T11:02:14.055358Z","shell.execute_reply":"2025-08-11T11:02:14.195818Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"vec = TfidfVectorizer()\nX_train_aug = vec.fit_transform(train_aug[\"text\"])\nX_test_aug = vec.transform(test_aug[\"text\"])\n\nclf = LogisticRegression(max_iter=2000, class_weight='balanced')\nclf.fit(X_train_aug, train_aug[\"label\"])\ny_pred_aug = clf.predict(X_test_aug)\n\nprint(classification_report(test_aug[\"label\"], y_pred_aug, zero_division=0))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:02:58.535980Z","iopub.execute_input":"2025-08-11T11:02:58.536782Z","iopub.status.idle":"2025-08-11T11:04:18.086274Z","shell.execute_reply.started":"2025-08-11T11:02:58.536752Z","shell.execute_reply":"2025-08-11T11:04:18.085436Z"}},"outputs":[{"name":"stdout","text":"                                      precision    recall  f1-score   support\n\n                      Mixed_feelings       0.18      0.35      0.24      1562\n                            Negative       0.18      0.20      0.19      1663\n                       Not_offensive       0.41      0.13      0.20     12723\n     Offensive_Targeted_Insult_Group       0.24      0.46      0.32      1256\nOffensive_Targeted_Insult_Individual       0.27      0.54      0.36      1186\n     Offensive_Targeted_Insult_Other       0.28      0.82      0.42       236\n               Offensive_Untargetede       0.29      0.51      0.37      1452\n                            Positive       0.36      0.38      0.37      7962\n                           not-Tamil       0.54      0.89      0.67      1341\n                       unknown_state       0.25      0.46      0.32      2214\n\n                            accuracy                           0.32     31595\n                           macro avg       0.30      0.47      0.35     31595\n                        weighted avg       0.35      0.32      0.30     31595\n\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"from transformers import MarianMTModel, MarianTokenizer\nimport torch\n\nmodel_name = \"Helsinki-NLP/opus-mt-mul-en\"\ntokenizer = MarianTokenizer.from_pretrained(model_name)\nmodel = MarianMTModel.from_pretrained(model_name)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ndef translate_texts(text_list):\n    inputs = tokenizer(text_list, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n    outputs = model.generate(**inputs)\n    return [tokenizer.decode(t, skip_special_tokens=True) for t in outputs]\n\nsample_texts = combined_df[\"augmented_text\"].head(5).tolist()\ntranslations = translate_texts(sample_texts)\n\nfor orig, trans in zip(sample_texts, translations):\n    print(f\"Original: {orig}\\nTranslated: {trans}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:04:40.932440Z","iopub.execute_input":"2025-08-11T11:04:40.932973Z","iopub.status.idle":"2025-08-11T11:04:43.303238Z","shell.execute_reply.started":"2025-08-11T11:04:40.932945Z","shell.execute_reply":"2025-08-11T11:04:43.302614Z"}},"outputs":[{"name":"stdout","text":"Original: movie vara level la poguthu erika\nTranslated: movie close to the level of the erika\n\nOriginal: i ajith love kumar vivegam movie inki mjy bht achi lgi\nTranslated: in the work of love komar\n\nOriginal: nalla padam comedy padama irukum polaye\nTranslated: I don't know what I'm going through.\n\nOriginal: karthick subburaj intha anne padam vetri adaya unagalukku ennudaya valthukkal\nTranslated: Karthick subburaj that's where the wind's gonna blow my head off the valthukal.\n\nOriginal: தேவர் கவுண்டர் சார்பாக வெற்றி பெற வாழ்த்துக்கள்\nTranslated: Life in God’s Service AS TOLD BY COUNTER\n\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"pip install indic-transliteration transformers torch sacrebleu emoji\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:07:52.799220Z","iopub.execute_input":"2025-08-11T11:07:52.799911Z","iopub.status.idle":"2025-08-11T11:07:56.081215Z","shell.execute_reply.started":"2025-08-11T11:07:52.799877Z","shell.execute_reply":"2025-08-11T11:07:56.080248Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: indic-transliteration in /usr/local/lib/python3.11/dist-packages (2.3.72)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\nRequirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (2.14.1)\nRequirement already satisfied: backports.functools-lru-cache in /usr/local/lib/python3.11/dist-packages (from indic-transliteration) (2.0.0)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from indic-transliteration) (2024.11.6)\nRequirement already satisfied: typer in /usr/local/lib/python3.11/dist-packages (from indic-transliteration) (0.16.0)\nRequirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from indic-transliteration) (0.10.2)\nRequirement already satisfied: roman in /usr/local/lib/python3.11/dist-packages (from indic-transliteration) (5.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.2.0)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer->indic-transliteration) (8.2.1)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer->indic-transliteration) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer->indic-transliteration) (14.0.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer->indic-transliteration) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer->indic-transliteration) (2.19.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->indic-transliteration) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"# Text, transliteration & regex\nimport re\nimport emoji\nfrom indic_transliteration import sanscript\nfrom indic_transliteration.sanscript import transliterate\n\n# Translation\nfrom transformers import MarianMTModel, MarianTokenizer\nimport torch\n\n# Evaluation\nimport sacrebleu\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:08:04.453463Z","iopub.execute_input":"2025-08-11T11:08:04.454336Z","iopub.status.idle":"2025-08-11T11:08:04.643606Z","shell.execute_reply.started":"2025-08-11T11:08:04.454301Z","shell.execute_reply":"2025-08-11T11:08:04.643032Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"def detect_token_language(token):\n    \"\"\"\n    Rough token-level language detection:\n    - Tamil unicode range chars → Tamil script\n    - Only English letters → English\n    - Otherwise → Romanized Tamil (heuristic)\n    \"\"\"\n    tamil_unicode_range = r'[\\u0B80-\\u0BFF]'\n    if re.search(tamil_unicode_range, token):\n        return \"tamil\"\n    elif re.match(r'^[a-zA-Z]+$', token):\n        return \"english\"\n    else:\n        return \"romanized_tamil\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:08:08.542224Z","iopub.execute_input":"2025-08-11T11:08:08.543743Z","iopub.status.idle":"2025-08-11T11:08:08.547710Z","shell.execute_reply.started":"2025-08-11T11:08:08.543715Z","shell.execute_reply":"2025-08-11T11:08:08.546883Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"def transliterate_roman_tamil_to_tamil(text):\n    try:\n        tamil_script = transliterate(text, sanscript.ITRANS, sanscript.TAMIL)\n        return tamil_script\n    except Exception:\n        return text  # fallback\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:08:15.805362Z","iopub.execute_input":"2025-08-11T11:08:15.805988Z","iopub.status.idle":"2025-08-11T11:08:15.809884Z","shell.execute_reply.started":"2025-08-11T11:08:15.805963Z","shell.execute_reply":"2025-08-11T11:08:15.809078Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"def preprocess_text(text):\n    \"\"\"\n    Steps:\n      1. Remove emojis\n      2. Tokenize text\n      3. Detect language of each token\n      4. Lowercase for English\n      5. Transliterate for Romanized Tamil\n    \"\"\"\n    # Remove emojis\n    text_no_emoji = emoji.replace_emoji(text, replace='')\n\n    tokens = text_no_emoji.split()\n    normalized_tokens = []\n\n    for token in tokens:\n        lang = detect_token_language(token)\n        if lang == \"english\":\n            normalized_tokens.append(token.lower())\n        elif lang == \"romanized_tamil\":\n            normalized_tokens.append(transliterate_roman_tamil_to_tamil(token))\n        else:  # Tamil script\n            normalized_tokens.append(token)\n\n    return \" \".join(normalized_tokens)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:08:20.612248Z","iopub.execute_input":"2025-08-11T11:08:20.612523Z","iopub.status.idle":"2025-08-11T11:08:20.617494Z","shell.execute_reply.started":"2025-08-11T11:08:20.612503Z","shell.execute_reply":"2025-08-11T11:08:20.616780Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"class Translator:\n    def __init__(self, model_name=\"Helsinki-NLP/opus-mt-mul-en\"):\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.tokenizer = MarianTokenizer.from_pretrained(model_name)\n        self.model = MarianMTModel.from_pretrained(model_name).to(self.device)\n\n    def translate(self, texts, batch_size=16):\n        results = []\n        for i in range(0, len(texts), batch_size):\n            batch = texts[i:i+batch_size]\n            inputs = self.tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True).to(self.device)\n            outputs = self.model.generate(**inputs)\n            decoded = [self.tokenizer.decode(t, skip_special_tokens=True) for t in outputs]\n            results.extend(decoded)\n        return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:08:29.554198Z","iopub.execute_input":"2025-08-11T11:08:29.554470Z","iopub.status.idle":"2025-08-11T11:08:29.560282Z","shell.execute_reply.started":"2025-08-11T11:08:29.554450Z","shell.execute_reply":"2025-08-11T11:08:29.559560Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"def evaluate_bleu(reference_texts, predicted_texts):\n    \"\"\"\n    Returns BLEU score between references and predictions\n    \"\"\"\n    bleu = sacrebleu.corpus_bleu(predicted_texts, [reference_texts])\n    return bleu.score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:08:38.452360Z","iopub.execute_input":"2025-08-11T11:08:38.452976Z","iopub.status.idle":"2025-08-11T11:08:38.456649Z","shell.execute_reply.started":"2025-08-11T11:08:38.452948Z","shell.execute_reply":"2025-08-11T11:08:38.455829Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Sample code-mixed Tamil-English sentences\n    samples = [\n        \"movie vara la level erika poguthu\",\n        \"i love ajith kumar vivegam movie inki mjy achi bht lgi\",\n        \"padam comedy nalla padama irukum polaye\",\n        \"கார்த்திக் சுப்புராஜ் அண்ணே இந்த படம் வெற்றி உங்கள் கடை எனது வாழ்த்துக்கள்\",\n        \"தேவர் கவுண்டர் சார்பாக வெற்றி பெற வாழ்த்துக்கள் 🦁\"\n    ]\n\n    # Step 1: Preprocess + normalize each sentence\n    preprocessed = [preprocess_text(s) for s in samples]\n    print(\"\\n--- Preprocessing Output ---\")\n    for orig, norm in zip(samples, preprocessed):\n        print(f\"Original: {orig}\\nNormalized: {norm}\\n\")\n\n    # Step 2: Translate normalized text\n    translator = Translator(model_name=\"Helsinki-NLP/opus-mt-mul-en\")\n    translations = translator.translate(preprocessed)\n\n    print(\"\\n--- Translation Output ---\")\n    for inp, trans in zip(preprocessed, translations):\n        print(f\"Input: {inp}\\nTranslated: {trans}\\n\")\n\n    # Step 3: Evaluate BLEU score (replace with real reference translations)\n    reference_translations = [\n        \"Movie is reaching next level\",\n        \"I love Ajith Kumar's Vivegam movie a lot\",\n        \"The movie is a good comedy film\",\n        \"Congratulations brother Karthik Subburaj on the success of this movie\",\n        \"Wishes for success on behalf of Devar Counter\"\n    ]\n    bleu_score = evaluate_bleu(reference_translations, translations)\n    print(f\"BLEU Score: {bleu_score:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:08:47.893283Z","iopub.execute_input":"2025-08-11T11:08:47.893780Z","iopub.status.idle":"2025-08-11T11:08:49.704353Z","shell.execute_reply.started":"2025-08-11T11:08:47.893754Z","shell.execute_reply":"2025-08-11T11:08:49.703719Z"}},"outputs":[{"name":"stdout","text":"\n--- Preprocessing Output ---\nOriginal: movie vara la level erika poguthu\nNormalized: movie vara la level erika poguthu\n\nOriginal: i love ajith kumar vivegam movie inki mjy achi bht lgi\nNormalized: i love ajith kumar vivegam movie inki mjy achi bht lgi\n\nOriginal: padam comedy nalla padama irukum polaye\nNormalized: padam comedy nalla padama irukum polaye\n\nOriginal: கார்த்திக் சுப்புராஜ் அண்ணே இந்த படம் வெற்றி உங்கள் கடை எனது வாழ்த்துக்கள்\nNormalized: கார்த்திக் சுப்புராஜ் அண்ணே இந்த படம் வெற்றி உங்கள் கடை எனது வாழ்த்துக்கள்\n\nOriginal: தேவர் கவுண்டர் சார்பாக வெற்றி பெற வாழ்த்துக்கள் 🦁\nNormalized: தேவர் கவுண்டர் சார்பாக வெற்றி பெற வாழ்த்துக்கள்\n\n\n--- Translation Output ---\nInput: movie vara la level erika poguthu\nTranslated: movie closes the level of total\n\nInput: i love ajith kumar vivegam movie inki mjy achi bht lgi\nTranslated: I love the love of life and the life of the movie\n\nInput: padam comedy nalla padama irukum polaye\nTranslated: I think I'm coming. I'm coming. I'm coming. I'm coming. I'm coming. I'm coming. I'm coming. I'm coming. I'm coming. I'm coming.\n\nInput: கார்த்திக் சுப்புராஜ் அண்ணே இந்த படம் வெற்றி உங்கள் கடை எனது வாழ்த்துக்கள்\nTranslated: The Kartik Queen won this picture and your life.\n\nInput: தேவர் கவுண்டர் சார்பாக வெற்றி பெற வாழ்த்துக்கள்\nTranslated: Life in God’s Service AS TOLD BY COUNTER\n\nBLEU Score: 1.48\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"ROMAN_TAMIL_SUFFIXES = (\"am\", \"um\", \"ai\", \"thu\", \"tha\", \"ana\", \"poga\", \"kathu\")\n\ndef detect_token_language(token):\n    tamil_unicode_range = r'[\\u0B80-\\u0BFF]'\n    token_lower = token.lower()\n    if re.search(tamil_unicode_range, token):\n        return \"tamil\"\n    elif token_lower.endswith(ROMAN_TAMIL_SUFFIXES):\n        return \"romanized_tamil\"\n    elif re.match(r'^[a-z]+$', token_lower):\n        return \"english\"\n    else:\n        return \"romanized_tamil\"\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:09:03.885345Z","iopub.execute_input":"2025-08-11T11:09:03.885627Z","iopub.status.idle":"2025-08-11T11:09:03.890385Z","shell.execute_reply.started":"2025-08-11T11:09:03.885604Z","shell.execute_reply":"2025-08-11T11:09:03.889502Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"def preprocess_text(text):\n    \"\"\"\n    1. Remove emojis\n    2. Tokenize text\n    3. Detect language per token\n    4. Lowercase English\n    5. Transliterate Romanized Tamil\n    \"\"\"\n    import emoji\n    text_no_emoji = emoji.replace_emoji(text, replace='')\n\n    tokens = text_no_emoji.split()\n    normalized_tokens = []\n\n    for token in tokens:\n        lang = detect_token_language(token)\n        if lang == \"english\":\n            normalized_tokens.append(token.lower())\n        elif lang == \"romanized_tamil\":\n            tamil_token = transliterate(token, sanscript.ITRANS, sanscript.TAMIL)\n            normalized_tokens.append(tamil_token)\n        else:  # already Tamil script\n            normalized_tokens.append(token)\n\n    return \" \".join(normalized_tokens)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:09:11.016280Z","iopub.execute_input":"2025-08-11T11:09:11.016554Z","iopub.status.idle":"2025-08-11T11:09:11.021628Z","shell.execute_reply.started":"2025-08-11T11:09:11.016532Z","shell.execute_reply":"2025-08-11T11:09:11.020991Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"samples = [\n    \"movie vara la level erika poguthu\",\n    \"padam comedy nalla padama irukum polaye\",\n    \"intha padam romba nalla iruku\"\n]\n\nfor s in samples:\n    print(s, \"→\", preprocess_text(s))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:09:19.022830Z","iopub.execute_input":"2025-08-11T11:09:19.023575Z","iopub.status.idle":"2025-08-11T11:09:19.028903Z","shell.execute_reply.started":"2025-08-11T11:09:19.023545Z","shell.execute_reply":"2025-08-11T11:09:19.028210Z"}},"outputs":[{"name":"stdout","text":"movie vara la level erika poguthu → movie vara la level erika போகுது\npadam comedy nalla padama irukum polaye → பதம் comedy nalla padama இருகும் polaye\nintha padam romba nalla iruku → இந்த பதம் romba nalla iruku\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"#common romanized Tamil words to suffix list so they get transliterated\nROMAN_TAMIL_SUFFIXES = (\n    \"am\", \"um\", \"ai\", \"thu\", \"tha\", \"ana\", \"poga\", \"kathu\", \"ka\", \"nga\",\n    \"ra\", \"la\", \"ya\", \"va\", \"cha\", \"pa\", \n    \"nalla\", \"romba\", \"polaye\", \"velai\", \"serthu\", \"irukku\", \"irukum\", \n    \"poguthu\", \"varuthu\", \"pattu\", \"kudutha\", \"padam\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:09:34.262742Z","iopub.execute_input":"2025-08-11T11:09:34.263023Z","iopub.status.idle":"2025-08-11T11:09:34.267561Z","shell.execute_reply.started":"2025-08-11T11:09:34.263000Z","shell.execute_reply":"2025-08-11T11:09:34.266596Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"samples = [\n    \"movie vara la level erika poguthu\",\n    \"padam comedy nalla padama irukum polaye\",\n    \"intha padam romba nalla irukku\"\n]\n\npreprocessed_samples = [preprocess_text(s) for s in samples]\n\nprint(\"\\n--- Preprocessed Output ---\")\nfor orig, norm in zip(samples, preprocessed_samples):\n    print(f\"{orig}  →  {norm}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:09:40.979762Z","iopub.execute_input":"2025-08-11T11:09:40.980047Z","iopub.status.idle":"2025-08-11T11:09:40.985043Z","shell.execute_reply.started":"2025-08-11T11:09:40.980025Z","shell.execute_reply":"2025-08-11T11:09:40.984497Z"}},"outputs":[{"name":"stdout","text":"\n--- Preprocessed Output ---\nmovie vara la level erika poguthu  →  movie வர ல level ஏரிக போகுது\npadam comedy nalla padama irukum polaye  →  பதம் comedy நல்ல padama இருகும் போலயே\nintha padam romba nalla irukku  →  இந்த பதம் ரோம்ப நல்ல இருக்கு\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"# Use MarianMT multilingual model\ntranslator = Translator(model_name=\"Helsinki-NLP/opus-mt-mul-en\")\ntranslations = translator.translate(preprocessed_samples)\n\nprint(\"\\n--- Translations ---\")\nfor norm, trans in zip(preprocessed_samples, translations):\n    print(f\"Input: {norm}\\nTranslated: {trans}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:09:49.262209Z","iopub.execute_input":"2025-08-11T11:09:49.262952Z","iopub.status.idle":"2025-08-11T11:09:50.647324Z","shell.execute_reply.started":"2025-08-11T11:09:49.262923Z","shell.execute_reply":"2025-08-11T11:09:50.646634Z"}},"outputs":[{"name":"stdout","text":"\n--- Translations ---\nInput: movie வர ல level ஏரிக போகுது\nTranslated: Level to add to the movie\n\nInput: பதம் comedy நல்ல padama இருகும் போலயே\nTranslated: The word comesdy as good as having a date.\n\nInput: இந்த பதம் ரோம்ப நல்ல இருக்கு\nTranslated: This word is good for Rome.\n\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"# Replace with your gold standard translations\nreference_translations = [\n    \"Movie is reaching next level\",\n    \"The movie is a good comedy film\",\n    \"This movie is very good\"\n]\n\nbleu = evaluate_bleu(reference_translations, translations)\nprint(f\"BLEU score: {bleu:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:09:59.172330Z","iopub.execute_input":"2025-08-11T11:09:59.172620Z","iopub.status.idle":"2025-08-11T11:09:59.177644Z","shell.execute_reply.started":"2025-08-11T11:09:59.172601Z","shell.execute_reply":"2025-08-11T11:09:59.176799Z"}},"outputs":[{"name":"stdout","text":"BLEU score: 3.04\n","output_type":"stream"}],"execution_count":65}]}